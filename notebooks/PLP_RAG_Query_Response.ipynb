{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88388585",
   "metadata": {},
   "source": [
    "\n",
    "# PLP Backend: Query–Response RAG Skeleton (with optional CoT-style reasoning)\n",
    "\n",
    "This notebook provides a minimal, **fully runnable** backend skeleton for your Personal Learning Portal (PLP) in **Corporate Finance**.  \n",
    "It implements:\n",
    "- Lightweight **ingestion → chunking → vector retrieval** (TF–IDF + cosine)\n",
    "- A simple **answer synthesizer** that cites sources\n",
    "- Optional, visible **“Reasoning steps” (CoT-style)** for teaching/learning transparency\n",
    "- Clean Python API: `answer(query, k=4, show_steps=True)`\n",
    "\n",
    "> No external APIs are required. You can later swap the vectorizer/LLM with your preferred stack (e.g., sentence-transformers + OpenAI) while keeping the same pipeline shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76164939",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== 0. Imports & Environment ====\n",
    "import os, math, json, textwrap, uuid\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"scikit-learn not found. Please install scikit-learn to run this notebook.\") from e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2572678",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Toy Learning Corpus (Corporate Finance)\n",
    "Below we create a **small, local corpus** with metadata so the pipeline runs end-to-end without internet.  \n",
    "Replace/extend this with your Phase‑3 curated sources (e.g., `data/corpus_sources.json` + actual text).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a65309",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== 1. In-memory corpus (replace with your own) ====\n",
    "\n",
    "toy_corpus = [\n",
    "    {\n",
    "        \"id\": \"doc_wacc_01\",\n",
    "        \"title\": \"Estimating Weighted Average Cost of Capital (WACC)\",\n",
    "        \"source\": \"Local notes\",\n",
    "        \"url\": \"local://wacc\",\n",
    "        \"text\": (\n",
    "            \"The weighted average cost of capital (WACC) is the average rate that a company is expected to pay to \"\n",
    "            \"finance its assets, weighted by the proportion of each financing source. WACC = E/V * Re + D/V * Rd * (1 - Tc), \"\n",
    "            \"where E is market value of equity, D is market value of debt, V=E+D, Re is cost of equity, Rd is cost of debt, \"\n",
    "            \"and Tc is corporate tax rate. WACC is used as a discount rate in NPV analysis when the project's risk is similar \"\n",
    "            \"to the firm's average risk profile.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_npv_01\",\n",
    "        \"title\": \"NPV and IRR Basics\",\n",
    "        \"source\": \"Local notes\",\n",
    "        \"url\": \"local://npv\",\n",
    "        \"text\": (\n",
    "            \"Net Present Value (NPV) discounts expected cash flows at an appropriate rate to determine project value. \"\n",
    "            \"NPV = sum(CFt / (1 + r)^t) - initial_investment. If NPV > 0, accept. The Internal Rate of Return (IRR) is the rate \"\n",
    "            \"that sets NPV to zero; it works best for conventional cash flows and when comparing projects of similar scale. \"\n",
    "            \"Payback period ignores time value of money and cash flows after cutoff.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_mm_01\",\n",
    "        \"title\": \"Modigliani–Miller with Taxes (Intuition)\",\n",
    "        \"source\": \"Local notes\",\n",
    "        \"url\": \"local://mm\",\n",
    "        \"text\": (\n",
    "            \"With corporate taxes, interest is tax-deductible, creating a tax shield that can make some leverage beneficial. \"\n",
    "            \"Trade-offs arise due to expected costs of financial distress and agency costs. In frictionless markets without taxes, \"\n",
    "            \"capital structure is irrelevant to firm value, but real-world frictions lead to target leverage considerations.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_div_01\",\n",
    "        \"title\": \"Dividend Policy and Signaling\",\n",
    "        \"source\": \"Local notes\",\n",
    "        \"url\": \"local://dividends\",\n",
    "        \"text\": (\n",
    "            \"Dividend policy involves choosing between distributing cash to shareholders and reinvesting earnings. \"\n",
    "            \"Firms often smooth dividends; changes may signal management’s expectations about sustainable cash flows. \"\n",
    "            \"Buybacks offer flexibility compared to regular dividends. In perfect markets, payout policy is irrelevant, \"\n",
    "            \"but taxes, transaction costs, and information asymmetry matter in practice.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_gov_01\",\n",
    "        \"title\": \"Governance and Agency in Corporate Finance\",\n",
    "        \"source\": \"Local notes\",\n",
    "        \"url\": \"local://governance\",\n",
    "        \"text\": (\n",
    "            \"Agency problems occur when managers’ incentives diverge from shareholders’. Governance mechanisms include boards, \"\n",
    "            \"executive compensation, ownership structure, and debt covenants. Transparent disclosure and investor protections \"\n",
    "            \"help mitigate agency costs and align decisions with long-term value.\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "len(toy_corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e810600f",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Preprocessing & Indexing\n",
    "We perform simple **sentence-level chunking** and build a **TF–IDF index** for retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d3bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== 2. Chunking ====\n",
    "import re\n",
    "\n",
    "def simple_sentence_split(text: str) -> List[str]:\n",
    "    # naive sentence splitter\n",
    "    sents = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "    return [s for s in sents if s]\n",
    "\n",
    "@dataclass\n",
    "class Chunk:\n",
    "    doc_id: str\n",
    "    chunk_id: str\n",
    "    title: str\n",
    "    url: str\n",
    "    text: str\n",
    "\n",
    "def build_chunks(corpus: List[Dict[str, Any]], max_sent_per_chunk: int = 2) -> List[Chunk]:\n",
    "    chunks = []\n",
    "    for doc in corpus:\n",
    "        sents = simple_sentence_split(doc[\"text\"])\n",
    "        for i in range(0, len(sents), max_sent_per_chunk):\n",
    "            piece = \" \".join(sents[i:i+max_sent_per_chunk])\n",
    "            chunks.append(\n",
    "                Chunk(\n",
    "                    doc_id=doc[\"id\"],\n",
    "                    chunk_id=f\"{doc['id']}::ch{i//max_sent_per_chunk}\",\n",
    "                    title=doc[\"title\"],\n",
    "                    url=doc[\"url\"],\n",
    "                    text=piece\n",
    "                )\n",
    "            )\n",
    "    return chunks\n",
    "\n",
    "chunks = build_chunks(toy_corpus, max_sent_per_chunk=2)\n",
    "len(chunks), chunks[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136be04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== 3. Vector Index (TF–IDF) ====\n",
    "\n",
    "class TfidfIndex:\n",
    "    def __init__(self, chunks: List[Chunk]):\n",
    "        self.chunks = chunks\n",
    "        self.vectorizer = TfidfVectorizer(ngram_range=(1,2), stop_words='english')\n",
    "        self.matrix = self.vectorizer.fit_transform([c.text for c in chunks])\n",
    "\n",
    "    def query(self, q: str, top_k: int = 5) -> List[Tuple[Chunk, float]]:\n",
    "        qv = self.vectorizer.transform([q])\n",
    "        sims = cosine_similarity(qv, self.matrix)[0]\n",
    "        idx = np.argsort(-sims)[:top_k]\n",
    "        return [(self.chunks[i], float(sims[i])) for i in idx]\n",
    "\n",
    "index = TfidfIndex(chunks)\n",
    "results = index.query(\"How do I compute WACC and when to use it?\", top_k=3)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acfd3c6",
   "metadata": {},
   "source": [
    "\n",
    "## 3. CoT-style Reasoning & Synthesis\n",
    "We generate **visible reasoning steps** (optional) and a final answer that **cites** the retrieved chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea312164",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== 4. Reasoner & Synthesizer ====\n",
    "\n",
    "def cot_plan(query: str) -> List[str]:\n",
    "    return [\n",
    "        \"1) Parse the question and identify key finance concepts.\",\n",
    "        \"2) Retrieve definitions/formulas and usage criteria from the corpus.\",\n",
    "        \"3) Cross-check retrieved evidence and select the most relevant chunks.\",\n",
    "        \"4) Synthesize an answer with definitions, formula(s), and when-to-use guidance.\",\n",
    "        \"5) List concise citations to source chunks.\"\n",
    "    ]\n",
    "\n",
    "def synthesize_answer(query: str, retrieved: List[Tuple[Chunk, float]], show_steps: bool=True) -> Dict[str, Any]:\n",
    "    # Build a short, grounded answer from retrieved chunks\n",
    "    bullet_evidence = []\n",
    "    for ch, score in retrieved:\n",
    "        snippet = textwrap.shorten(ch.text, width=220, placeholder=\"…\")\n",
    "        bullet_evidence.append(f\"- [{ch.doc_id}] {snippet} (score={score:.3f})\")\n",
    "\n",
    "    # Very simple \"generation\": stitch relevant pieces\n",
    "    # In practice, replace with your LLM call and keep citations.\n",
    "    top_texts = \" \".join([ch.text for ch, _ in retrieved])\n",
    "\n",
    "    # Heuristic: if WACC mentioned, include formula; if NPV/IRR mentioned, add usage\n",
    "    answer_lines = []\n",
    "    qt = query.lower()\n",
    "    if \"wacc\" in qt or \"cost of capital\" in qt:\n",
    "        answer_lines.append(\n",
    "            \"Weighted Average Cost of Capital (WACC) is the firm’s blended discount rate: \"\n",
    "            \"WACC = E/V·Re + D/V·Rd·(1−Tc). Use it as the discount rate for projects with risk similar to the firm’s core assets.\"\n",
    "        )\n",
    "    if \"npv\" in qt or \"irr\" in qt:\n",
    "        answer_lines.append(\n",
    "            \"NPV discounts expected cash flows at an appropriate rate; accept if NPV>0. \"\n",
    "            \"IRR is the rate that sets NPV=0; works best for conventional cash flows and comparable scale projects.\"\n",
    "        )\n",
    "    if not answer_lines:\n",
    "        # default summary from retrieved\n",
    "        answer_lines.append(textwrap.shorten(top_texts, width=500, placeholder=\"…\"))\n",
    "\n",
    "    citations = [{\"doc_id\": ch.doc_id, \"chunk_id\": ch.chunk_id, \"url\": ch.url} for ch, _ in retrieved]\n",
    "\n",
    "    out = {\n",
    "        \"query\": query,\n",
    "        \"answer\": \" \".join(answer_lines),\n",
    "        \"citations\": citations\n",
    "    }\n",
    "    if show_steps:\n",
    "        out[\"reasoning_steps\"] = cot_plan(query) + bullet_evidence\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c6fa3",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Public API\n",
    "Use `answer(query, k=4, show_steps=True)` to run the full pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40783d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== 5. Public API ====\n",
    "\n",
    "def answer(query: str, k: int = 4, show_steps: bool=True) -> Dict[str, Any]:\n",
    "    retrieved = index.query(query, top_k=k)\n",
    "    return synthesize_answer(query, retrieved, show_steps=show_steps)\n",
    "\n",
    "# Quick smoke tests\n",
    "demo1 = answer(\"How do I compute WACC and when should I use it as a discount rate?\")\n",
    "demo2 = answer(\"Compare NPV and IRR and mention a limitation of payback.\", show_steps=False)\n",
    "\n",
    "demo1, demo2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11a3875",
   "metadata": {},
   "source": [
    "\n",
    "## 5. (Optional) Extend: Ingest Your Own Corpus\n",
    "Use `ingest_documents()` to add your texts (e.g., from SEC filings, textbooks).  \n",
    "Rebuild the index with `rebuild_index()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175352b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== 6. Ingestion Helpers ====\n",
    "\n",
    "def ingest_documents(docs: List[Dict[str, str]]):\n",
    "    \"\"\"docs: list of dicts with keys: id, title, url, text\"\"\"\n",
    "    ids = {d[\"id\"] for d in toy_corpus}\n",
    "    for d in docs:\n",
    "        if d[\"id\"] in ids:\n",
    "            raise ValueError(f\"Duplicate id: {d['id']}\")\n",
    "        toy_corpus.append(d)\n",
    "\n",
    "def rebuild_index(max_sent_per_chunk: int = 2):\n",
    "    global chunks, index\n",
    "    chunks = build_chunks(toy_corpus, max_sent_per_chunk=max_sent_per_chunk)\n",
    "    index = TfidfIndex(chunks)\n",
    "\n",
    "# Example (commented):\n",
    "# ingest_documents([\n",
    "#     {\"id\":\"doc_custom_01\",\"title\":\"My notes on CAPM\",\"url\":\"local://capm\",\"text\":\"Cost of equity can be estimated via CAPM: Re = Rf + beta*(ERP).\"},\n",
    "# ])\n",
    "# rebuild_index()\n",
    "# answer(\"How to estimate cost of equity using CAPM?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95f3ce6",
   "metadata": {},
   "source": [
    "\n",
    "## 6. (Optional) Plug-in Points\n",
    "- **Embeddings**: swap TF–IDF with sentence embeddings (e.g., `sentence-transformers`)  \n",
    "- **Reranking**: add a cross-encoder or a BM25 first-stage + cross-encoder reranker  \n",
    "- **LLM**: replace `synthesize_answer()` with an LLM call, keep the `citations` contract  \n",
    "- **Eval**: log queries/answers and compute groundedness/faithfulness with RAGAs/ARES later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b42ee6",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Minimal CLI\n",
    "Uncomment and run the cell to ask interactive questions inside the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb571081",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== 7. Minimal CLI (optional) ====\n",
    "# while True:\n",
    "#     q = input(\"Ask a corporate-finance question (or 'quit'): \").strip()\n",
    "#     if q.lower() in {\"quit\", \"exit\"}:\n",
    "#         break\n",
    "#     resp = answer(q, k=4, show_steps=True)\n",
    "#     print(\"\\nAnswer:\", resp[\"answer\"])\n",
    "#     print(\"Citations:\", json.dumps(resp[\"citations\"], indent=2))\n",
    "#     print(\"Reasoning:\", *resp.get(\"reasoning_steps\", []), sep=\"\\n- \")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}